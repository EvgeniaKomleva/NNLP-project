{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Quick NLG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.11 64-bit ('torchtext': conda)"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python",
      "version": "3.7.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "a524880a5bb876edaae9b7b15baff302663c5354b3341491bbd2f8257d44506d"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Viuf5RhzKG00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing the required packages"
      ],
      "metadata": {
        "id": "sf1uUqSEKKgk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in ./transformers/src (4.19.0.dev0)\n",
            "Requirement already satisfied: filelock in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from transformers) (2022.3.15)\n",
            "Requirement already satisfied: requests in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: sacremoses in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: importlib_metadata in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from importlib_metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from requests->transformers) (1.26.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: six in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n",
            "Requirement already satisfied: joblib in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.4)\n",
            "Requirement already satisfied: sentencepiece in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (0.1.96)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6ki1-m-5UUA",
        "outputId": "5bb54de8-e804-448d-fee4-2fc19d4f9099"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "0cxu1nJO4dGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required libraries"
      ],
      "metadata": {
        "id": "CalKR6o4KP22"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers.optimization import  Adafactor \n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "outputs": [],
      "metadata": {
        "id": "CB6rH4GenWpN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "4GZK-pXuKUw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess the data"
      ],
      "metadata": {
        "id": "-aWMq3DOKl34"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "train_df=pd.read_csv('cur_train.csv', index_col=[0])"
      ],
      "outputs": [],
      "metadata": {
        "id": "BQ2uifxUnVgk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "train_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  prefix                                         input_text  \\\n",
              "0    cur  40.87 Philippine pesos)| 40.87 | Philippine pe...   \n",
              "1    cur                               LD 800 | 800 | LD |    \n",
              "2    cur                   thirty lepta | thirty | lepta |    \n",
              "3    cur  Renminbi two hundred fifty-four thousand five ...   \n",
              "4    cur           100,000 drachmae.| 100,000 | drachmae.|    \n",
              "\n",
              "                                         target_text  \n",
              "0  An army commander said two dozen people had be...  \n",
              "1  outnumbering the population. The militia which...  \n",
              "2  On arrival in Athens, her immediate patronages...  \n",
              "3  2.3 The first three months of the lease term i...  \n",
              "4  Nicolaus and Josephus mention that during Juli...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prefix</th>\n",
              "      <th>input_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cur</td>\n",
              "      <td>40.87 Philippine pesos)| 40.87 | Philippine pe...</td>\n",
              "      <td>An army commander said two dozen people had be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cur</td>\n",
              "      <td>LD 800 | 800 | LD |</td>\n",
              "      <td>outnumbering the population. The militia which...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cur</td>\n",
              "      <td>thirty lepta | thirty | lepta |</td>\n",
              "      <td>On arrival in Athens, her immediate patronages...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cur</td>\n",
              "      <td>Renminbi two hundred fifty-four thousand five ...</td>\n",
              "      <td>2.3 The first three months of the lease term i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cur</td>\n",
              "      <td>100,000 drachmae.| 100,000 | drachmae.|</td>\n",
              "      <td>Nicolaus and Josephus mention that during Juli...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gEf2Moir1W8I",
        "outputId": "ee6ac71c-aec8-4058-ff0c-14d9c1b7bd6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trimming off a few data points and so that a batch would not leave any remainder, hence some lines of codes can be avoided (Okay, this might be a hackish way of doing it )"
      ],
      "metadata": {
        "id": "j_dPYbsVK5zO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "train_df=train_df.iloc[  :35000,:]"
      ],
      "outputs": [],
      "metadata": {
        "id": "-WpyPzBKyXf1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "train_df=train_df.sample(frac = 1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "WgsIcgFgRCwN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "batch_size=1\n",
        "num_of_batches=len(train_df)/batch_size\n",
        "num_of_epochs=4"
      ],
      "outputs": [],
      "metadata": {
        "id": "zGfaigiqnZW5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "num_of_batches=int(num_of_batches)"
      ],
      "outputs": [],
      "metadata": {
        "id": "SQDfdl3mxYf_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "L_QyyxbkKXf2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for the GPU availability"
      ],
      "metadata": {
        "id": "9kfjkXbiKeyU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "if torch.cuda.is_available():\n",
        "    dev = torch.device(\"cuda:0\") \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    dev = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on the GPU\n"
          ]
        }
      ],
      "metadata": {
        "id": "nHkcKfKRr1BC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b568136-d3a3-4391-dfc6-3b31682c4fb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the pretrained model and tokenizer"
      ],
      "metadata": {
        "id": "_JaUpURdLAla"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base', return_dict=True)\n",
        "#moving the model to device(GPU/CPU)\n",
        "model.to(dev)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64ecc633e2de407da5b16fb27c467422"
            }
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "id": "xVAXjd6wsOM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372e30ca-5429-434b-cee9-a360b96c6db9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "Dx0uCmTvLJFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing the Adafactor optimizer with parameter values suggested for t5"
      ],
      "metadata": {
        "id": "C4oqM6giLLg4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "optimizer = Adafactor(\n",
        "    model.parameters(),\n",
        "    lr=1e-3,\n",
        "    eps=(1e-30, 1e-3),\n",
        "    clip_threshold=1.0,\n",
        "    decay_rate=-0.8,\n",
        "    beta1=None,\n",
        "    weight_decay=0.0,\n",
        "    relative_step=False,\n",
        "    scale_parameter=False,\n",
        "    warmup_init=False\n",
        ")\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "1KmOzTQj0E7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3ggfjCkdLcar"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def progress(loss,value, max=100):\n",
        "    return HTML(\"\"\" Batch loss :{loss}\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(loss=loss,value=value, max=max))"
      ],
      "outputs": [],
      "metadata": {
        "id": "wXw1NKtS1YV3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "num_of_epochs=4"
      ],
      "outputs": [],
      "metadata": {
        "id": "6i7zx4DmC_ap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model"
      ],
      "metadata": {
        "id": "hMe1hKshLgJn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Sets the module in training mode\n",
        "model.train()\n",
        "\n",
        "loss_per_10_steps=[]\n",
        "for epoch in range(1,num_of_epochs+1):\n",
        "  print('Running epoch: {}'.format(epoch))\n",
        "  \n",
        "  running_loss=0\n",
        "\n",
        "  out = display(progress(1, num_of_batches+1), display_id=True)\n",
        "  for i in range(num_of_batches):\n",
        "    inputbatch=[]\n",
        "    labelbatch=[]\n",
        "    new_df=train_df[i*batch_size:i*batch_size+batch_size]\n",
        "    for indx,row in new_df.iterrows():\n",
        "      input = 'cur: '+row['input_text']+'</s>' \n",
        "      labels = row['target_text']+'</s>'   \n",
        "      inputbatch.append(input)\n",
        "      labelbatch.append(labels)\n",
        "    inputbatch=tokenizer.batch_encode_plus(inputbatch,padding=True,max_length=400,return_tensors='pt')[\"input_ids\"]\n",
        "    labelbatch=tokenizer.batch_encode_plus(labelbatch,padding=True,max_length=400,return_tensors=\"pt\") [\"input_ids\"]\n",
        "    inputbatch=inputbatch.to(dev)\n",
        "    labelbatch=labelbatch.to(dev)\n",
        "\n",
        "    # clear out the gradients of all Variables \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward propogation\n",
        "    outputs = model(input_ids=inputbatch, labels=labelbatch)\n",
        "    loss = outputs.loss\n",
        "    loss_num=loss.item()\n",
        "    logits = outputs.logits\n",
        "    running_loss+=loss_num\n",
        "    if i%10 ==0:      \n",
        "      loss_per_10_steps.append(loss_num)\n",
        "    out.update(progress(loss_num,i, num_of_batches+1))\n",
        "\n",
        "    # calculating the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    #updating the params\n",
        "    optimizer.step()\n",
        "    \n",
        "  running_loss=running_loss/int(num_of_batches)\n",
        "  print('Epoch: {} , Running loss: {}'.format(epoch,running_loss))\n",
        "  "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running epoch: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " Batch loss :4.210197448730469\n",
              "        <progress\n",
              "            value='6'\n",
              "            max='828',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            6\n",
              "        </progress>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6994a4563ef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Forward propogation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabelbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mloss_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m             \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1671\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1672\u001b[0m             \u001b[0;31m# TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1164\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 320.00 MiB (GPU 0; 14.76 GiB total capacity; 12.60 GiB already allocated; 313.75 MiB free; 13.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "metadata": {
        "id": "qTvda_lWx2nC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "8aba844f-53e5-4ebd-e566-6795622606ec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the loss over time"
      ],
      "metadata": {
        "id": "UwVEDrdZ545G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import matplotlib.pyplot as plt\n",
        "   \n",
        "steps = [i*100 for i in range(len(loss_per_10_steps))]\n",
        "  \n",
        "plt.plot(steps, loss_per_10_steps)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "7quhDpSxxTGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model"
      ],
      "metadata": {
        "id": "Nv3VHD585lc9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.eval()\n",
        "input_ids = tokenizer.encode(\"WebNLG: sidharth | hometown | Delhi && sidharth | play |  football </s>\", return_tensors=\"pt\")  # Batch size 1\n",
        "input_ids=input_ids.to(dev)\n",
        "outputs = model.generate(input_ids)\n",
        "tokenizer.decode(outputs[0])"
      ],
      "outputs": [],
      "metadata": {
        "id": "JD6M4tb8l2Vs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before testing the model further, lets learn how to serialize it and load from the path"
      ],
      "metadata": {
        "id": "owrlOe0L62WK"
      }
    }
  ]
}