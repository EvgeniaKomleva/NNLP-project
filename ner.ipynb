{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import ipdb\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import razdel\n",
    "from razdel import tokenize\n",
    "from collections import Counter, namedtuple\n",
    "from enum import IntEnum\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping  \n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from ipymarkup import show_box_markup\n",
    "from ipymarkup.palette import palette, BLUE, RED, GREEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../irregular_train_fixed.csv')\n",
    "df2 = pd.read_csv('../regular_train_fixed.csv')\n",
    "df = pd.concat([df, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../irregular_test_fixed.csv')\n",
    "df2_test = pd.read_csv('../regular_test_fixed.csv')\n",
    "df_test = pd.concat([df_test, df2_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tar_pos_l</th>\n",
       "      <th>tar_pos_r</th>\n",
       "      <th>amount</th>\n",
       "      <th>currency</th>\n",
       "      <th>amount_pos_l</th>\n",
       "      <th>amount_pos_r</th>\n",
       "      <th>currency_pos_l</th>\n",
       "      <th>currency_pos_r</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DUAL SERVICE ",
       "MEMORANDUM OF AGREEMENT FOR EMPLO...</td>\n",
       "      <td>['$ 1000', '$ 1332.3', '$ 3150.75']</td>\n",
       "      <td>[1386, 1610, 1110]</td>\n",
       "      <td>[1395, 1619, 1119]</td>\n",
       "      <td>['1000', '1332.3', '3150.75']</td>\n",
       "      <td>['$', '$', '$']</td>\n",
       "      <td>[1387, 1611, 1111]</td>\n",
       "      <td>[1395, 1619, 1119]</td>\n",
       "      <td>[1386, 1610, 1110]</td>\n",
       "      <td>[1387, 1611, 1111]</td>\n",
       "      <td>data/rdf_unregular_eng/train\\100031_ForML2.pdf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DUAL SERVICE ",
       "MEMORANDUM OF AGREEMENT FOR EMPLO...</td>\n",
       "      <td>['$ 2108.45']</td>\n",
       "      <td>[1098]</td>\n",
       "      <td>[1107]</td>\n",
       "      <td>['2108.45']</td>\n",
       "      <td>['$']</td>\n",
       "      <td>[1099]</td>\n",
       "      <td>[1107]</td>\n",
       "      <td>[1098]</td>\n",
       "      <td>[1099]</td>\n",
       "      <td>data/rdf_unregular_eng/train\\100068_ForML1.pdf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>07-0088 ",
       "DUAL SERVICE ",
       "MEMORANDUM OF AGREEMENT F...</td>\n",
       "      <td>['$ 2708.3', '$ 1294.15', '$ 1294.15', '$ 1414...</td>\n",
       "      <td>[1722, 1851, 1018, 1168, 1190]</td>\n",
       "      <td>[1731, 1860, 1027, 1177, 1199]</td>\n",
       "      <td>['2708.3', '1294.15', '1294.15', '1414.15', '2...</td>\n",
       "      <td>['$', '$', '$', '$', '$']</td>\n",
       "      <td>[1723, 1852, 1019, 1169, 1191]</td>\n",
       "      <td>[1731, 1860, 1027, 1177, 1199]</td>\n",
       "      <td>[1722, 1851, 1018, 1168, 1190]</td>\n",
       "      <td>[1723, 1852, 1019, 1169, 1191]</td>\n",
       "      <td>data/rdf_unregular_eng/train\\100086_ForML1.pdf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DUAL SERVICE ",
       "MEMORANDUM OF AGREEMENT FOR EMPLO...</td>\n",
       "      <td>['$ 3889.5']</td>\n",
       "      <td>[1967]</td>\n",
       "      <td>[1976]</td>\n",
       "      <td>['3889.5']</td>\n",
       "      <td>['$']</td>\n",
       "      <td>[1968]</td>\n",
       "      <td>[1976]</td>\n",
       "      <td>[1967]</td>\n",
       "      <td>[1968]</td>\n",
       "      <td>data/rdf_unregular_eng/train\\100120_ForML1.pdf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DUAL SERVICE ",
       "MEMORANDUM OF AGREEMENT FOR EMPLO...</td>\n",
       "      <td>['$ 1296.5']</td>\n",
       "      <td>[1731]</td>\n",
       "      <td>[1740]</td>\n",
       "      <td>['1296.5']</td>\n",
       "      <td>['$']</td>\n",
       "      <td>[1732]</td>\n",
       "      <td>[1740]</td>\n",
       "      <td>[1731]</td>\n",
       "      <td>[1732]</td>\n",
       "      <td>data/rdf_unregular_eng/train\\100121_ForML1.pdf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>4528</td>\n",
       "      <td>Windows (4.5%, 11/243), Nokia (2.5%, 6/243), a...</td>\n",
       "      <td>['$ 0.99', '$ 15.99', '$ 4.99', 'CAN $ 3.15']</td>\n",
       "      <td>[578, 587, 662, 552]</td>\n",
       "      <td>[583, 593, 667, 561]</td>\n",
       "      <td>['0.99', '15.99', '4.99', '3.15']</td>\n",
       "      <td>['$', '$', '$', 'CAN $']</td>\n",
       "      <td>[579, 588, 663, 557]</td>\n",
       "      <td>[583, 593, 667, 561]</td>\n",
       "      <td>[578, 587, 662, 552]</td>\n",
       "      <td>[579, 588, 663, 557]</td>\n",
       "      <td>data/rdf_regular_eng/Train\\CAN_dollar (35).doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4529</th>\n",
       "      <td>4529</td>\n",
       "      <td>In 2006, Rights &amp; Democracy concluded 3-year p...</td>\n",
       "      <td>['CAN$ 200000']</td>\n",
       "      <td>[89]</td>\n",
       "      <td>[101]</td>\n",
       "      <td>['200000']</td>\n",
       "      <td>['CAN$']</td>\n",
       "      <td>[94]</td>\n",
       "      <td>[101]</td>\n",
       "      <td>[89]</td>\n",
       "      <td>[93]</td>\n",
       "      <td>data/rdf_regular_eng/Train\\CAN_dollar (36).doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>4530</td>\n",
       "      <td>Mentioning that the Stolt LNGaz project was va...</td>\n",
       "      <td>['US$ 600000000', 'CAN$ 800000000']</td>\n",
       "      <td>[64, 94]</td>\n",
       "      <td>[78, 109]</td>\n",
       "      <td>['600000000', '800000000']</td>\n",
       "      <td>['US$', 'CAN$']</td>\n",
       "      <td>[67, 98]</td>\n",
       "      <td>[78, 109]</td>\n",
       "      <td>[64, 94]</td>\n",
       "      <td>[67, 98]</td>\n",
       "      <td>data/rdf_regular_eng/Train\\CAN_dollar (37).doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4531</th>\n",
       "      <td>4531</td>\n",
       "      <td>CAN$1,000,000 is approximately equal to $709,3...</td>\n",
       "      <td>['$ 709319', 'US$ 70932', 'CAN$ 1000000', 'CAN...</td>\n",
       "      <td>[40, 91, 0, 53, 132, 138]</td>\n",
       "      <td>[48, 100, 13, 64, 137, 149]</td>\n",
       "      <td>['709319', '70932', '1000000', '100000', '1', ...</td>\n",
       "      <td>['$', 'US$', 'CAN$', 'CAN$', 'CAN$', 'US$']</td>\n",
       "      <td>[41, 94, 4, 57, 136, 141]</td>\n",
       "      <td>[48, 100, 13, 64, 137, 149]</td>\n",
       "      <td>[40, 91, 0, 53, 132, 138]</td>\n",
       "      <td>[41, 94, 4, 57, 136, 141]</td>\n",
       "      <td>data/rdf_regular_eng/Train\\CAN_dollar (4).docx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>4532</td>\n",
       "      <td>The jury awarded CAN$318,252 in compensatory d...</td>\n",
       "      <td>['CAN$ 318252', 'CAN$ 1000000']</td>\n",
       "      <td>[17, 57]</td>\n",
       "      <td>[28, 70]</td>\n",
       "      <td>['318252', '1000000']</td>\n",
       "      <td>['CAN$', 'CAN$']</td>\n",
       "      <td>[21, 61]</td>\n",
       "      <td>[28, 70]</td>\n",
       "      <td>[17, 57]</td>\n",
       "      <td>[21, 61]</td>\n",
       "      <td>data/rdf_regular_eng/Train\\CAN_dollar (6).docx...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5296 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  \\\n",
       "0              0  DUAL SERVICE\n",
       "MEMORANDUM OF AGREEMENT FOR EMPLO...   \n",
       "1              1  DUAL SERVICE\n",
       "MEMORANDUM OF AGREEMENT FOR EMPLO...   \n",
       "2              2  07-0088\n",
       "DUAL SERVICE\n",
       "MEMORANDUM OF AGREEMENT F...   \n",
       "3              3  DUAL SERVICE\n",
       "MEMORANDUM OF AGREEMENT FOR EMPLO...   \n",
       "4              4  DUAL SERVICE\n",
       "MEMORANDUM OF AGREEMENT FOR EMPLO...   \n",
       "...          ...                                                ...   \n",
       "4528        4528  Windows (4.5%, 11/243), Nokia (2.5%, 6/243), a...   \n",
       "4529        4529  In 2006, Rights & Democracy concluded 3-year p...   \n",
       "4530        4530  Mentioning that the Stolt LNGaz project was va...   \n",
       "4531        4531  CAN$1,000,000 is approximately equal to $709,3...   \n",
       "4532        4532  The jury awarded CAN$318,252 in compensatory d...   \n",
       "\n",
       "                                                 target  \\\n",
       "0                   ['$ 1000', '$ 1332.3', '$ 3150.75']   \n",
       "1                                         ['$ 2108.45']   \n",
       "2     ['$ 2708.3', '$ 1294.15', '$ 1294.15', '$ 1414...   \n",
       "3                                          ['$ 3889.5']   \n",
       "4                                          ['$ 1296.5']   \n",
       "...                                                 ...   \n",
       "4528      ['$ 0.99', '$ 15.99', '$ 4.99', 'CAN $ 3.15']   \n",
       "4529                                    ['CAN$ 200000']   \n",
       "4530                ['US$ 600000000', 'CAN$ 800000000']   \n",
       "4531  ['$ 709319', 'US$ 70932', 'CAN$ 1000000', 'CAN...   \n",
       "4532                    ['CAN$ 318252', 'CAN$ 1000000']   \n",
       "\n",
       "                           tar_pos_l                       tar_pos_r  \\\n",
       "0                 [1386, 1610, 1110]              [1395, 1619, 1119]   \n",
       "1                             [1098]                          [1107]   \n",
       "2     [1722, 1851, 1018, 1168, 1190]  [1731, 1860, 1027, 1177, 1199]   \n",
       "3                             [1967]                          [1976]   \n",
       "4                             [1731]                          [1740]   \n",
       "...                              ...                             ...   \n",
       "4528            [578, 587, 662, 552]            [583, 593, 667, 561]   \n",
       "4529                            [89]                           [101]   \n",
       "4530                        [64, 94]                       [78, 109]   \n",
       "4531       [40, 91, 0, 53, 132, 138]     [48, 100, 13, 64, 137, 149]   \n",
       "4532                        [17, 57]                        [28, 70]   \n",
       "\n",
       "                                                 amount  \\\n",
       "0                         ['1000', '1332.3', '3150.75']   \n",
       "1                                           ['2108.45']   \n",
       "2     ['2708.3', '1294.15', '1294.15', '1414.15', '2...   \n",
       "3                                            ['3889.5']   \n",
       "4                                            ['1296.5']   \n",
       "...                                                 ...   \n",
       "4528                  ['0.99', '15.99', '4.99', '3.15']   \n",
       "4529                                         ['200000']   \n",
       "4530                         ['600000000', '800000000']   \n",
       "4531  ['709319', '70932', '1000000', '100000', '1', ...   \n",
       "4532                              ['318252', '1000000']   \n",
       "\n",
       "                                         currency  \\\n",
       "0                                 ['$', '$', '$']   \n",
       "1                                           ['$']   \n",
       "2                       ['$', '$', '$', '$', '$']   \n",
       "3                                           ['$']   \n",
       "4                                           ['$']   \n",
       "...                                           ...   \n",
       "4528                     ['$', '$', '$', 'CAN $']   \n",
       "4529                                     ['CAN$']   \n",
       "4530                              ['US$', 'CAN$']   \n",
       "4531  ['$', 'US$', 'CAN$', 'CAN$', 'CAN$', 'US$']   \n",
       "4532                             ['CAN$', 'CAN$']   \n",
       "\n",
       "                        amount_pos_l                    amount_pos_r  \\\n",
       "0                 [1387, 1611, 1111]              [1395, 1619, 1119]   \n",
       "1                             [1099]                          [1107]   \n",
       "2     [1723, 1852, 1019, 1169, 1191]  [1731, 1860, 1027, 1177, 1199]   \n",
       "3                             [1968]                          [1976]   \n",
       "4                             [1732]                          [1740]   \n",
       "...                              ...                             ...   \n",
       "4528            [579, 588, 663, 557]            [583, 593, 667, 561]   \n",
       "4529                            [94]                           [101]   \n",
       "4530                        [67, 98]                       [78, 109]   \n",
       "4531       [41, 94, 4, 57, 136, 141]     [48, 100, 13, 64, 137, 149]   \n",
       "4532                        [21, 61]                        [28, 70]   \n",
       "\n",
       "                      currency_pos_l                  currency_pos_r  \\\n",
       "0                 [1386, 1610, 1110]              [1387, 1611, 1111]   \n",
       "1                             [1098]                          [1099]   \n",
       "2     [1722, 1851, 1018, 1168, 1190]  [1723, 1852, 1019, 1169, 1191]   \n",
       "3                             [1967]                          [1968]   \n",
       "4                             [1731]                          [1732]   \n",
       "...                              ...                             ...   \n",
       "4528            [578, 587, 662, 552]            [579, 588, 663, 557]   \n",
       "4529                            [89]                            [93]   \n",
       "4530                        [64, 94]                        [67, 98]   \n",
       "4531       [40, 91, 0, 53, 132, 138]       [41, 94, 4, 57, 136, 141]   \n",
       "4532                        [17, 57]                        [21, 61]   \n",
       "\n",
       "                                               filename  \n",
       "0     data/rdf_unregular_eng/train\\100031_ForML2.pdf...  \n",
       "1     data/rdf_unregular_eng/train\\100068_ForML1.pdf...  \n",
       "2     data/rdf_unregular_eng/train\\100086_ForML1.pdf...  \n",
       "3     data/rdf_unregular_eng/train\\100120_ForML1.pdf...  \n",
       "4     data/rdf_unregular_eng/train\\100121_ForML1.pdf...  \n",
       "...                                                 ...  \n",
       "4528  data/rdf_regular_eng/Train\\CAN_dollar (35).doc...  \n",
       "4529  data/rdf_regular_eng/Train\\CAN_dollar (36).doc...  \n",
       "4530  data/rdf_regular_eng/Train\\CAN_dollar (37).doc...  \n",
       "4531  data/rdf_regular_eng/Train\\CAN_dollar (4).docx...  \n",
       "4532  data/rdf_regular_eng/Train\\CAN_dollar (6).docx...  \n",
       "\n",
       "[5296 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tar_pos_l</th>\n",
       "      <th>tar_pos_r</th>\n",
       "      <th>amount</th>\n",
       "      <th>currency</th>\n",
       "      <th>amount_pos_l</th>\n",
       "      <th>amount_pos_r</th>\n",
       "      <th>currency_pos_l</th>\n",
       "      <th>currency_pos_r</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DUAL SERVICE ",
       "MEMORANDUM OF AGREEMENT FOR EMPLO...</td>\n",
       "      <td>['$ 1000']</td>\n",
       "      <td>[1505]</td>\n",
       "      <td>[1515]</td>\n",
       "      <td>['1000']</td>\n",
       "      <td>['$']</td>\n",
       "      <td>[1507]</td>\n",
       "      <td>[1515]</td>\n",
       "      <td>[1505]</td>\n",
       "      <td>[1506]</td>\n",
       "      <td>data/rdf_unregular_eng/test\\100413_ForML2.pdf.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AGREEMENT ",
       "THIS AGREEMENT, macle and entered in...</td>\n",
       "      <td>['S 3700000']</td>\n",
       "      <td>[374]</td>\n",
       "      <td>[384]</td>\n",
       "      <td>['3700000']</td>\n",
       "      <td>['S']</td>\n",
       "      <td>[375]</td>\n",
       "      <td>[384]</td>\n",
       "      <td>[374]</td>\n",
       "      <td>[375]</td>\n",
       "      <td>data/rdf_unregular_eng/test\\100533_ForML1.pdf.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This Instrument Prepared By: ",
       "Middle Tennessee ...</td>\n",
       "      <td>['$_____ 27600']</td>\n",
       "      <td>[1947]</td>\n",
       "      <td>[1959]</td>\n",
       "      <td>['27600']</td>\n",
       "      <td>['$_____']</td>\n",
       "      <td>[1953]</td>\n",
       "      <td>[1959]</td>\n",
       "      <td>[1947]</td>\n",
       "      <td>[1953]</td>\n",
       "      <td>data/rdf_unregular_eng/test\\100619_ForML1.pdf.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DUAL SERVICE ",
       "MEMORANDUM OF AGREEMENT FOR EMPLO...</td>\n",
       "      <td>['$ 2014.75']</td>\n",
       "      <td>[1464]</td>\n",
       "      <td>[1473]</td>\n",
       "      <td>['2014.75']</td>\n",
       "      <td>['$']</td>\n",
       "      <td>[1465]</td>\n",
       "      <td>[1473]</td>\n",
       "      <td>[1464]</td>\n",
       "      <td>[1465]</td>\n",
       "      <td>data/rdf_unregular_eng/test\\100716_ForML1.pdf.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DUAL SERVICE ",
       "MEMORANDUM OF AGREEMENT FOR EMPLO...</td>\n",
       "      <td>['$ 110', '$ 110']</td>\n",
       "      <td>[1808, 968]</td>\n",
       "      <td>[1816, 976]</td>\n",
       "      <td>['110', '110']</td>\n",
       "      <td>['$', '$']</td>\n",
       "      <td>[1809, 969]</td>\n",
       "      <td>[1816, 976]</td>\n",
       "      <td>[1808, 968]</td>\n",
       "      <td>[1809, 969]</td>\n",
       "      <td>data/rdf_unregular_eng/test\\100732_ForML1.pdf.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>1593</td>\n",
       "      <td>As part of his compensation for the financial ...</td>\n",
       "      <td>['CAN $ 1400000', 'CAN $ 2285000', 'CAN $ 3675...</td>\n",
       "      <td>[197, 213, 232, 342, 393, 447]</td>\n",
       "      <td>[211, 227, 246, 351, 402, 456]</td>\n",
       "      <td>['1400000', '2285000', '3675000', '3.50', '4.6...</td>\n",
       "      <td>['CAN $', 'CAN $', 'CAN $', 'CAN $', 'CAN $', ...</td>\n",
       "      <td>[202, 218, 237, 347, 398, 452]</td>\n",
       "      <td>[211, 227, 246, 351, 402, 456]</td>\n",
       "      <td>[197, 213, 232, 342, 393, 447]</td>\n",
       "      <td>[202, 218, 237, 347, 398, 452]</td>\n",
       "      <td>data/rdf_regular_eng/Test\\CAN_dollar (38).docx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1594</td>\n",
       "      <td>In that case, the plaintiff purchased a house ...</td>\n",
       "      <td>['CAN$ 88000', 'CAN$ 271000', 'CAN$ 121000', '...</td>\n",
       "      <td>[50, 254, 293, 333, 403]</td>\n",
       "      <td>[60, 265, 304, 344, 413]</td>\n",
       "      <td>['88000', '271000', '121000', '150000', '18900']</td>\n",
       "      <td>['CAN$', 'CAN$', 'CAN$', 'CAN$', 'CAN$']</td>\n",
       "      <td>[54, 258, 297, 337, 407]</td>\n",
       "      <td>[60, 265, 304, 344, 413]</td>\n",
       "      <td>[50, 254, 293, 333, 403]</td>\n",
       "      <td>[54, 258, 297, 337, 407]</td>\n",
       "      <td>data/rdf_regular_eng/Test\\CAN_dollar (5).docx.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1595</td>\n",
       "      <td>If you have been outside Canada for: ",
       "24 hours ...</td>\n",
       "      <td>['CAN$ 200', 'CAN$ 800']</td>\n",
       "      <td>[72, 333]</td>\n",
       "      <td>[79, 340]</td>\n",
       "      <td>['200', '800']</td>\n",
       "      <td>['CAN$', 'CAN$']</td>\n",
       "      <td>[76, 337]</td>\n",
       "      <td>[79, 340]</td>\n",
       "      <td>[72, 333]</td>\n",
       "      <td>[76, 337]</td>\n",
       "      <td>data/rdf_regular_eng/Test\\CAN_dollar (7).docx.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1596</td>\n",
       "      <td>Some operations of Bombardier are conducted un...</td>\n",
       "      <td>['CAN$ 20000000']</td>\n",
       "      <td>[1198]</td>\n",
       "      <td>[1212]</td>\n",
       "      <td>['20000000']</td>\n",
       "      <td>['CAN$']</td>\n",
       "      <td>[1202]</td>\n",
       "      <td>[1212]</td>\n",
       "      <td>[1198]</td>\n",
       "      <td>[1202]</td>\n",
       "      <td>data/rdf_regular_eng/Test\\CAN_dollar (8).docx.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1597</td>\n",
       "      <td>The holders of Class B Subordinate Voting Shar...</td>\n",
       "      <td>['CAN$ 0.000390625', 'CAN$ 0.025', 'CAN$ 0.001...</td>\n",
       "      <td>[193, 1248, 155]</td>\n",
       "      <td>[208, 1257, 168]</td>\n",
       "      <td>['0.000390625', '0.025', '0.0015625']</td>\n",
       "      <td>['CAN$', 'CAN$', 'CAN$']</td>\n",
       "      <td>[197, 1252, 159]</td>\n",
       "      <td>[208, 1257, 168]</td>\n",
       "      <td>[193, 1248, 155]</td>\n",
       "      <td>[197, 1252, 159]</td>\n",
       "      <td>data/rdf_regular_eng/Test\\CAN_dollar (9).docx.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1880 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  \\\n",
       "0              0  DUAL SERVICE\n",
       "MEMORANDUM OF AGREEMENT FOR EMPLO...   \n",
       "1              1  AGREEMENT\n",
       "THIS AGREEMENT, macle and entered in...   \n",
       "2              2  This Instrument Prepared By:\n",
       "Middle Tennessee ...   \n",
       "3              3  DUAL SERVICE\n",
       "MEMORANDUM OF AGREEMENT FOR EMPLO...   \n",
       "4              4  DUAL SERVICE\n",
       "MEMORANDUM OF AGREEMENT FOR EMPLO...   \n",
       "...          ...                                                ...   \n",
       "1593        1593  As part of his compensation for the financial ...   \n",
       "1594        1594  In that case, the plaintiff purchased a house ...   \n",
       "1595        1595  If you have been outside Canada for:\n",
       "24 hours ...   \n",
       "1596        1596  Some operations of Bombardier are conducted un...   \n",
       "1597        1597  The holders of Class B Subordinate Voting Shar...   \n",
       "\n",
       "                                                 target  \\\n",
       "0                                            ['$ 1000']   \n",
       "1                                         ['S 3700000']   \n",
       "2                                      ['$_____ 27600']   \n",
       "3                                         ['$ 2014.75']   \n",
       "4                                    ['$ 110', '$ 110']   \n",
       "...                                                 ...   \n",
       "1593  ['CAN $ 1400000', 'CAN $ 2285000', 'CAN $ 3675...   \n",
       "1594  ['CAN$ 88000', 'CAN$ 271000', 'CAN$ 121000', '...   \n",
       "1595                           ['CAN$ 200', 'CAN$ 800']   \n",
       "1596                                  ['CAN$ 20000000']   \n",
       "1597  ['CAN$ 0.000390625', 'CAN$ 0.025', 'CAN$ 0.001...   \n",
       "\n",
       "                           tar_pos_l                       tar_pos_r  \\\n",
       "0                             [1505]                          [1515]   \n",
       "1                              [374]                           [384]   \n",
       "2                             [1947]                          [1959]   \n",
       "3                             [1464]                          [1473]   \n",
       "4                        [1808, 968]                     [1816, 976]   \n",
       "...                              ...                             ...   \n",
       "1593  [197, 213, 232, 342, 393, 447]  [211, 227, 246, 351, 402, 456]   \n",
       "1594        [50, 254, 293, 333, 403]        [60, 265, 304, 344, 413]   \n",
       "1595                       [72, 333]                       [79, 340]   \n",
       "1596                          [1198]                          [1212]   \n",
       "1597                [193, 1248, 155]                [208, 1257, 168]   \n",
       "\n",
       "                                                 amount  \\\n",
       "0                                              ['1000']   \n",
       "1                                           ['3700000']   \n",
       "2                                             ['27600']   \n",
       "3                                           ['2014.75']   \n",
       "4                                        ['110', '110']   \n",
       "...                                                 ...   \n",
       "1593  ['1400000', '2285000', '3675000', '3.50', '4.6...   \n",
       "1594   ['88000', '271000', '121000', '150000', '18900']   \n",
       "1595                                     ['200', '800']   \n",
       "1596                                       ['20000000']   \n",
       "1597              ['0.000390625', '0.025', '0.0015625']   \n",
       "\n",
       "                                               currency  \\\n",
       "0                                                 ['$']   \n",
       "1                                                 ['S']   \n",
       "2                                            ['$_____']   \n",
       "3                                                 ['$']   \n",
       "4                                            ['$', '$']   \n",
       "...                                                 ...   \n",
       "1593  ['CAN $', 'CAN $', 'CAN $', 'CAN $', 'CAN $', ...   \n",
       "1594           ['CAN$', 'CAN$', 'CAN$', 'CAN$', 'CAN$']   \n",
       "1595                                   ['CAN$', 'CAN$']   \n",
       "1596                                           ['CAN$']   \n",
       "1597                           ['CAN$', 'CAN$', 'CAN$']   \n",
       "\n",
       "                        amount_pos_l                    amount_pos_r  \\\n",
       "0                             [1507]                          [1515]   \n",
       "1                              [375]                           [384]   \n",
       "2                             [1953]                          [1959]   \n",
       "3                             [1465]                          [1473]   \n",
       "4                        [1809, 969]                     [1816, 976]   \n",
       "...                              ...                             ...   \n",
       "1593  [202, 218, 237, 347, 398, 452]  [211, 227, 246, 351, 402, 456]   \n",
       "1594        [54, 258, 297, 337, 407]        [60, 265, 304, 344, 413]   \n",
       "1595                       [76, 337]                       [79, 340]   \n",
       "1596                          [1202]                          [1212]   \n",
       "1597                [197, 1252, 159]                [208, 1257, 168]   \n",
       "\n",
       "                      currency_pos_l                  currency_pos_r  \\\n",
       "0                             [1505]                          [1506]   \n",
       "1                              [374]                           [375]   \n",
       "2                             [1947]                          [1953]   \n",
       "3                             [1464]                          [1465]   \n",
       "4                        [1808, 968]                     [1809, 969]   \n",
       "...                              ...                             ...   \n",
       "1593  [197, 213, 232, 342, 393, 447]  [202, 218, 237, 347, 398, 452]   \n",
       "1594        [50, 254, 293, 333, 403]        [54, 258, 297, 337, 407]   \n",
       "1595                       [72, 333]                       [76, 337]   \n",
       "1596                          [1198]                          [1202]   \n",
       "1597                [193, 1248, 155]                [197, 1252, 159]   \n",
       "\n",
       "                                               filename  \n",
       "0     data/rdf_unregular_eng/test\\100413_ForML2.pdf.xml  \n",
       "1     data/rdf_unregular_eng/test\\100533_ForML1.pdf.xml  \n",
       "2     data/rdf_unregular_eng/test\\100619_ForML1.pdf.xml  \n",
       "3     data/rdf_unregular_eng/test\\100716_ForML1.pdf.xml  \n",
       "4     data/rdf_unregular_eng/test\\100732_ForML1.pdf.xml  \n",
       "...                                                 ...  \n",
       "1593  data/rdf_regular_eng/Test\\CAN_dollar (38).docx...  \n",
       "1594  data/rdf_regular_eng/Test\\CAN_dollar (5).docx.xml  \n",
       "1595  data/rdf_regular_eng/Test\\CAN_dollar (7).docx.xml  \n",
       "1596  data/rdf_regular_eng/Test\\CAN_dollar (8).docx.xml  \n",
       "1597  data/rdf_regular_eng/Test\\CAN_dollar (9).docx.xml  \n",
       "\n",
       "[1880 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    data = list()\n",
    "    tar_pos_l = df['tar_pos_l'].values\n",
    "    tar_pos_r = df['tar_pos_r'].values\n",
    "    text = df['text'].values\n",
    "    for i in range(df.shape[0]):\n",
    "        text_i = text[i]\n",
    "        try:\n",
    "            tar_pos_l_i = list(map(int, tar_pos_l[i].strip(\"'[]'\").split(', ')))\n",
    "            tar_pos_r_i = list(map(int, tar_pos_r[i].strip(\"'[]'\").split(', ')))\n",
    "        except ValueError:\n",
    "            continue\n",
    "        data.append( (text_i, [(l, r, 'TAR') for l, r in zip(tar_pos_l_i, tar_pos_r_i)]) )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(df)\n",
    "data_test = prepare_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">DUAL SERVICE ",
       "MEMORANDUM OF AGREEMENT FOR EMPLOYEE SERVICES ",
       "Nashville State Community College VENDOR PARTY ",
       "Tennessee Board of Regents PROCURING PARTY ",
       "This memorandum signifies agreement of the above parties concerning the provision of employee services. The agreement is as follows: ",
       "1.      Vendor agrees to furnish the services of its employee: ",
       "Name of Employee: Jim Formosa____________________________ ",
       "Social Security No.               _______ ____________________ ",
       "Address I City / zip code: ",
       "email: Jim.formosa@nscc.edu              Phone: (615)353-3420              who ",
       "will perform the following services for procuring party: Tennessee Board of Regents: Description of Services: Faculty Mentors for RODP- (See attached job description) ",
       "2. Compensation to vendor party (includes cost of any applicable staff benefits to vendor&#x27;s employee for service under this agreement) ",
       "Fall 2006: $2,500.00 base pay plus $155.00 FICA @ 6.2%, $36.25 Medicare @ 1.45%; $339.50 Retirement @ 13.58% (TCRS) = $3,030.75 plus travel not to exceed $120.00 (paid pursuant to TBR travel policy 4:03:03:00) for a total not to exceed <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">$3,150,75<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">TAR</span></span>. ",
       "Spring 2007: $2,500.00 base pay plus $155.00 FICA @ 6.2%, $36.25 Medicare @ 1.45%; $339.50 Retirement @ 13.58% (TCRS) = $3,030.75 plus travel not to exceed $120.00 (paid pursuant to TBR travel policy 4:03:03:00) for a total not to exceed $3,150.75. ",
       "Summer I, 2007: <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">$1.000.00<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">TAR</span></span> base pay plus $62.00 FICA @ 6.2%; $14.50 Medicare @ 1.45%; Retirement @ 13.58% $135.80 (TCRS) = $1,212.30 plus travel not to exceed $120.00 (paid pursuant to TBR travel policy 4:03:03:00) for a total not to exceed <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">$1.332.30<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">TAR</span></span> ",
       "Maximum liability of procuring party $7,633.80 of contract ",
       "3. Payment will be made by procuring party after completion of service and after receipt of invoice from vendor party mailed to the following address: ",
       "Deanna Hall ",
       "Tennessee Board of Regents ",
       "1415 Murfreesboro Road ",
       "Nashville, TN 37217-2833 ",
       "Payment will be made in three (3) installments: ",
       "1st Installment (Fall 2006) on or after Dec. 16,2006 2nd Installment (Spring 2007) on or after April 30,2007 3rd Installment (Summer 1,2007) on or after June 29,2007 ",
       "4.     Contract term: July 1.2006- June 30,2007 ",
       "5.      Either party may terminate this agreement by giving written notice to the other at least 30 days before the effective date of termination. In that event, vendor shall be entitled to receive just and equitable compensation for any satisfactory work completed as of the termination date. In addition, procuring party shall have the right to immediately terminate this agreement and withhold payments in excess of fair compensation for work completed in the event that the employee fails to perform in a timely and proper manner or breaches any material term of this agreement. ",
       "6.     This agreement cannot be assigned or subcontracted without the written consent of all parties. ",
       "Dated this 18th day of July, 2006. ",
       "NASHVILLE STATE COMMUNITY COLLEGE ",
       "By ",
       "By: ",
       "Date ",
       "Title: ",
       "Date: ",
       "Date:</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_box_markup(data[0][0], data[0][1], palette=palette(TAR=BLUE, ORG=RED, LOC=GREEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">07-0088 ",
       "DUAL SERVICE ",
       "MEMORANDUM OF AGREEMENT FOR EMPLOYEE SERVICES ",
       "Middle Tennessee State University ",
       "VENDOR PARTY ",
       "Tennessee Board of Regents PROCURING PARTY ",
       "This memorandum signifies agreement of the above parties concerning the provision of employee services. The agreement is as follows: ",
       "1 .Vendor agrees to furnish the services of its employee: ",
       "Name of Employee:    Maria A. Smith_____________________ ",
       "Social Security No. 421-70-9851 Address/ City I zip code:3119 Bilbrey Drive, Murfreesboro, TN 37129 email:    massmith@mtsu.edu Phone: 615-898-5844____________________________________ ",
       "who will perform the following services for procuring party: Tennessee Board of Regents ",
       "Description of Services: Program Mentor for MSN-RODP - (See attached job description) ",
       "2. Compensation to vendor party (includes cost of any applicable staff benefits to vendor&#x27;s employee for service under this agreement) ",
       "Summer II. 2006: $1,100.00 base pay plus $68.20 FICA @ 6.2%, $15.95 Medicare @ 1.45%, $110..00 retirement @ 10% (ORP) = <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">$1.294,15<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">TAR</span></span> plus travel not to exceed $120.00 (Travel to be paid in accordance with the current TBR Travel Policy 4:03:03:00) for a total not to exceed <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">$1.414.15<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">TAR</span></span>. ",
       "Fall 2006: <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">$2.200.00<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">TAR</span></span> base pay plus $ 136.40 FICA @ 6.2%, $31.90 Medicare @ 1.45%, $220.00 retirement @ 10% (ORP) = $2,588.30 plus travel not to exceed $120.00 (Travel to be paid in accordance with the current TBR Travel Policy 4:03:03:00) for a total not to exceed $2,708.30. ",
       "Spring 2007: $2,200.00 base pay plus $ 136.40 FICA @ 6.2%, $31.90 Medicare @ 1.45%, $220.00 retirement @ 10% (ORP) = $2,588.30 plus travel not to exceed $120.00 (Travel to be paid in accordance with the current TBR Travel Policy 4:03:03:00) for a total not to exceed <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">$2.708.30<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">TAR</span></span>. ",
       "Summer 1,2007: $1,100.00 base pay plus $68.20 FICA @ 6.2%, $15.95 Medicare @ 1.45%, $110.00 retirement @ 10% (ORP ) = <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">$1.294.15<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">TAR</span></span>. ",
       "Maximum liability of procuring party $8,124.90 of contract. ",
       "3. Payment will be made by procuring party after completion of service and after receipt of invoice from vendor party mailed to the following address: ",
       "Deanna Hall, Director of Fiscal Services ",
       "1415 Murfreesboro Rd., Suite 350 Nashville, TN 37217-2833 ",
       "Payment will be made in four (4) installments: ",
       "07-0088 ",
       "1st Installment (Summer II, 2006) due on or after Aug. 13, 2006 ",
       "2nd Installment (Fall 2006) due on or after Dec. 13,2006 ",
       "3rd Installment (Spring 2007) due on or after April 30,2007 4th Installment (Summer 1,2007) due on or after June 29,2007 ",
       "4. Contract time and term: July 1.2006 - June 30,2007 ",
       "5. Either party may terminate this agreement by giving written notice to the other at least 30 days before the effective date of termination. In that event, vendor shall be entitled to receive just and equitable compensation for any satisfactory work completed as of the termination date. In addition, procuring party shall have the right to immediately terminate this agreement and withhold payments in excess of fair compensation for work completed in the event that the employee fails to perform in a timely and proper manner or breaches any material term of this agreement. ",
       "6. This agreement cannot be assigned or subcontracted without the written consent of all parties. ",
       "Dated this 24th day of May, 2006 ",
       "UNIVERSITY ",
       "By: ",
       "Date: ",
       "John W. Cothern ■&#x27;?riior Vice President ",
       "LE TENNESSEE STAT ",
       "’BbkoQ) ",
       "By: ______________________________ ",
       "Employee ",
       "Date: ________________________________ ",
       "TENNESSEE BOARD OF REGENTS ",
       "By: ",
       "Charles Manning, Chancellor ",
       "Date:                    ___________________________</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.BEGIN: 1>, <Label.INNER: 2>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.BEGIN: 1>, <Label.INNER: 2>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.BEGIN: 1>, <Label.INNER: 2>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.BEGIN: 1>, <Label.INNER: 2>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.BEGIN: 1>, <Label.INNER: 2>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>, <Label.OUTER: 0>]\n",
      "5255\n",
      "1858\n"
     ]
    }
   ],
   "source": [
    "class Label(IntEnum):\n",
    "    OUTER = 0\n",
    "    BEGIN = 1\n",
    "    INNER = 2\n",
    "\n",
    "Sample = namedtuple(\"Sample\", \"text,tokens,spans,labels\")\n",
    "it = 0\n",
    "def text_span_to_sample(text, spans):\n",
    "    labels = []\n",
    "    tokens = list(tokenize(text))\n",
    "    \n",
    "    for token in tokens:\n",
    "        label = Label.OUTER\n",
    "        for span in spans:\n",
    "            # Начало или часть какого-то спана\n",
    "            # Не совсем корректно из-за возможных различий разметки и токенизации\n",
    "            span_begin, span_end, tag = span\n",
    "            if token.start == span_begin:\n",
    "                label = Label.BEGIN\n",
    "            elif token.start > span_begin and token.stop <= span_end:\n",
    "                label = Label.INNER\n",
    "        labels.append(label)\n",
    "\n",
    "    # Проверяем инвариант отсутствия последовательных пар (0, 2)\n",
    "    try:\n",
    "        assert len([1 for i in range(len(labels) - 1) if (labels[i], labels[i+1]) == (0, 2)]) == 0\n",
    "        return Sample(text, tokens, spans, labels)\n",
    "    except AssertionError:\n",
    "        pass\n",
    "    \n",
    "\n",
    "samples = []\n",
    "for text, spans in data:\n",
    "    samples.append(text_span_to_sample(text, spans))\n",
    "\n",
    "test_samples = []\n",
    "for text, spans in data_test:\n",
    "    test_samples.append(text_span_to_sample(text, spans))\n",
    "    \n",
    "show_box_markup(samples[2].text, samples[2].spans, palette=palette(PER=BLUE, ORG=RED, LOC=GREEN))\n",
    "print(samples[2].labels)\n",
    "print(len(samples))\n",
    "print(len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(test_samples)\n",
    "val = test_samples[:1000]\n",
    "test = test_samples[1000:]\n",
    "train = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_none(sample):\n",
    "    for entry in sample:\n",
    "        if entry == None:\n",
    "            sample.remove(entry)\n",
    "        \n",
    "remove_none(val)\n",
    "remove_none(test)\n",
    "remove_none(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '<unk>', '用', 'ក', 'ย', 'd', 'ৃ', 'ˌ', 'Х', '護', '₨', 'Χ', '”', '<', 'ɪ', 'ো', '刑', '乐', '\\u200b', 'ử', '厂', 'ھ', '格', 'ິ', '再', '籍', 'մ', '\\uf06e', '；', 'ت', 'ơ', 'S', 'ư', 'у', 'p', 'φ', '鏡', '£', 'Θ', 'ä', '狀', '□', 'ে', '7', 'δ', '牌', '＜', '³', 'B', '燃', 'Æ', '4', 'ē', '®', 'व', 'ậ', '軌', 'б', 'т', 'თ', 'h', 'ិ', 'ת', 'ぐ', 'ע', '×', 'P', '香', 'ã', 'イ', '「', '{', 'ự', 'μ', '院', '円', 'ق', '廣', '½', 'W', 'Z', 'ā', 'ল', 'চ', '=', '।', 'à', '物', 'ß', '度', 'হ', '廠', '蘇', 'ے', 'น', '※', 'հ', 'ẫ', '/', '制', 'П', 'Ш', 'q', '）', '♦', 'ד', '業', '温', 'ě', '月', 'ū', '【', '逸', 'と', '文', 'σ', 'מ', 'ہ', '«', 'K', 'ỹ', '娛', 'บ', '฿', '真', '御', 'な', 'ի', '₴', 'ᥤ', 'ק', 'đ', 'К', '¡', 'Λ', 'ն', '機', 'ö', '⅛', 'ع', '₭', '1', 'Þ', '灣', '水', '隆', 'є', 'ن', '泰', '火', '•', '典', '信', 'ᥢ', 'e', 'ɨ', '★', 'ï', 'ầ', 'ε', '₦', '榜', 'R', 'ئ', 'Н', '₯', 'ì', '₾', 'I', '傭', 'ν', 'ი', 'O', 'ǔ', 'j', '】', '动', 'Г', 'п', 'р', 'o', 'ა', '极', '輕', 'N', 'ř', '交', '力', 'G', '‐', '#', '₮', '設', '篙', 'গ', 'ī', 'ឹ', '保', 'ც', 'ި', 'u', 'स', '奥', 'ъ', 'ả', 'ǎ', '景', '₩', 'Π', 'n', 'ô', 'Д', 'ý', '駅', 'l', 'گ', 'র', 'の', 'ụ', '澡', 'Ч', '限', '橘', '電', '网', 'ッ', '»', '⅔', 'ề', '诺', 'უ', 'ɫ', '៛', 'ø', '樹', '恒', 'ز', 'ສ', 'ọ', '%', 'ნ', 'ǒ', '5', 'រ', 'ή', 'ê', 'ї', 'ñ', 'ğ', 'å', 'ش', '¼', '罰', 'โ', '্', \"'\", '鉢', 'ł', 'λ', '2', 'Ľ', '―', 'ϋ', 'چ', '五', '&', 'â', 'ާ', 'Y', 'О', '*', '瑞', 'Č', '\\\\', 'ס', 'X', 'ό', 'ս', 'ű', 'ć', '9', 'に', 'ރ', '▼', '■', '©', 'a', 'ซ', '–', ']', '飞', 'Ì', 'س', 'k', 'খ', 'J', 'ệ', 'ą', '思', 'ب', 'î', '@', '券', 'ο', 'ج', 'в', 'ן', 'ố', 'ợ', '₹', '″', '�', ',', 'Ć', 'ь', 'জ', 'ˈ', 'Я', 'i', '之', '書', 'ц', 'Å', '迪', 'び', 'ុ', 'Á', 'ί', '一', 'ك', 'ч', '尔', 'ʁ', 'ท', '城', 'ي', '়', 'ы', 'ő', 'Î', '錢', 'স', '`', '￦', '江', '海', 'Ç', 'T', 'এ', 'и', '財', '尼', '竹', '样', 'ލ', 'r', 'υ', 'ा', '园', 'Ü', 'ผ', '行', '樂', 'ά', 'و', 'L', 'ω', '⁄', 'v', 'ź', 'ا', '＞', '輪', 'އ', 'ổ', '?', 'ນ', 'ও', '寸', 'ı', 'z', '△', 'ů', 'շ', 'ვ', 'ù', '—', '求', 'γ', 'Ș', '6', '曼', 'ন', '৭', '\\u200e', 'Š', 'ƒ', 'V', 'پ', 'H', '\"', 'η', '科', '‑', '日', '霆', 'る', 'յ', 'ĕ', '!', '有', 'ষ', 'я', 'ス', 'Ф', '借', 'ễ', 'д', 'ধ', '京', 'ر', 'ស', 'Û', '‘', 'm', 'ח', 'з', '發', 'ラ', 'ó', 'ს', 'ʝ', '°', '¢', '家', 'ʻ', '₤', 'ș', '}', '^', 'g', 'տ', '浙', 'ی', 'Ñ', ':', 'ฮ', '8', '₡', 'ю', '广', '3', 'г', '庫', 'ń', '吳', 'ւ', '₺', '夫', '…', 'ত', '奧', '技', '什', '￡', 'і', 'ម', 'ل', 'н', 'y', 'Ś', 'Ż', '台', 'ל', '[', 'ก', 'ờ', '−', '部', 'ň', 'נ', '漫', 'ว', '无', '司', 'к', 'を', '〇', 'ĩ', '国', 'Ō', '上', 'ه', 'ו', 'ớ', 'ছ', '汽', 'f', '’', '十', '熱', '-', '，', '™', '्', 'श', 'া', '換', '北', '.', '§', '港', 'ؤ', 'ç', '貫', 'ա', 'ג', 'י', '₵', 'л', '昭', 'ť', 'Р', 'দ', 'উ', 'У', 'β', 'Ե', '่', 'থ', 'ক', 'ü', '을', 's', '₪', 'ð', '+', '\\xad', 'x', 'ᥔ', 'ْ', 'æ', '가', '“', 'ں', 'о', 'ᥲ', 'ú', 'ო', '娱', '鈴', 'ง', '金', 'َ', 'ж', 'ই', 'เ', '雲', '东', '装', 'ṭ', '白', '环', 'Հ', '環', 'פ', 'π', 'Q', 'อ', 'ȉ', 'א', '>', 'č', 'ة', 'ẵ', '乾', 'ث', 'ศ', '本', 'Đ', '≤', 'ế', 'ι', '로', 'ু', 'დ', '´', 'ạ', 'ş', 'Ö', '法', '৳', '年', 'ف', '￥', 'c', 'আ', 'Ł', 'り', '花', 'ỳ', 'C', '₱', 'د', 't', 'А', '€', '(', '：', 'ÿ', ';', 'ប', 'ភ', 'ộ', 'ż', 'b', '는', 'À', '化', 'ò', 'ė', '►', '動', '្', '′', 'й', 'õ', '相', 'ด', 'İ', '້', '份', 'ম', '₫', 'ứ', '้', 'è', 'ไ', 'ា', 'ă', '車', 'প', '六', '\\u200f', 'ঢ', '築', '±', '好', 'ถ', '雷', 'ک', 'м', 'α', 'ิ', '理', 'ţ', 'Ø', 'า', 'ś', '·', 'パ', 'É', '士', 'ジ', '؟', 'ّ', 'Ē', 'í', '商', 'š', '利', 'ρ', '氣', 'ৎ', 'D', 'ُ', 'Ἀ', 'Í', '和', 'U', 'ե', '차', '$', 'م', '工', '股', '₧', '影', 'Ú', 'ր', 'Ž', 'С', '№', 'ắ', 'á', 'ž', '业', '外', 'ę', 'M', '杵', '庭', 'ồ', '恩', 'с', '²', 'χ', 'w', 'Т', 'য', '„', 'ո', '기', '少', 'A', '~', 'τ', 'В', '球', 'শ', 'ë', 'ɛ', 'а', 'բ', '飛', 'ڑ', 'プ', 'е', '₽', '￠', '0', '〜', 'κ', 'ō', 'E', 'آ', '|', 'Δ', '≈', 'ɾ', 'F', '¥', '络', '⅓', '公', 'З', '\\ufeff', 'ល', 'ț', '匚', 'Б', 'ি', '屋', ')', 'х', '_', '王', '银', 'é', '葉', '東', 'ট']\n"
     ]
    }
   ],
   "source": [
    "char_set = [\"<pad>\", \"<unk>\"] + list({ch for sample in train for token in sample.tokens for ch in token.text})\n",
    "print(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11751"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = samples[0]\n",
    "\n",
    "max_seq_len = 0\n",
    "max_char_seq_len = 0\n",
    "\n",
    "for sample in samples:\n",
    "    max_seq_len = max(len(sample.tokens), max_seq_len)\n",
    "    for token in sample.tokens:\n",
    "        max_char_seq_len = max(len(token.text), max_char_seq_len)\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "class NerCharsDataset(Dataset):\n",
    "    def __init__(self, samples, char_set, max_seq_len=500, max_char_seq_len=50):\n",
    "        assert len(samples) != 0\n",
    "        self.samples = []\n",
    "        self.tokens = []\n",
    "        self.texts = []\n",
    "        for sample in samples:\n",
    "            inputs = torch.zeros((max_seq_len, max_char_seq_len), dtype=torch.long)\n",
    "            for token_num, token in enumerate(sample.tokens[:max_seq_len]):\n",
    "                for ch_num, ch in enumerate(token.text[:max_char_seq_len]):\n",
    "                    char_index = char_set.index(ch) if ch in char_set else char_set.index(\"<unk>\")\n",
    "                    inputs[token_num][ch_num] = char_index\n",
    "            labels = torch.zeros((max_seq_len), dtype=torch.long)\n",
    "            input_labels = [int(i) for i in sample.labels[:max_seq_len]]\n",
    "            labels[:len(input_labels)] = torch.LongTensor(input_labels)\n",
    "            self.samples.append((torch.LongTensor(inputs), torch.LongTensor(labels)))\n",
    "            self.tokens.append(sample.tokens[:max_seq_len])\n",
    "            self.texts.append(sample.text)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.samples[index]\n",
    "\n",
    "    def get_tokens(self, index):\n",
    "        return self.tokens[index]\n",
    "    \n",
    "    def get_text(self, index):\n",
    "        return self.texts[index]\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = NerCharsDataset(train, char_set)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "\n",
    "val_data = NerCharsDataset(val, char_set)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_data = NerCharsDataset(test, char_set)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 500, 50])\n",
      "torch.Size([32, 500])\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = batch\n",
    "print(inputs.size())\n",
    "print(labels.size())\n",
    "\n",
    "# inputs: batch_size x num_words x num_chars\n",
    "# labels: batch_size x num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[400,   0,   0,  ...,   0,   0,   0],\n",
       "        [347,  60, 318,  ...,   0,   0,   0],\n",
       "        [  5, 154, 286,  ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0,  ...,   0,   0,   0],\n",
       "        [  0,   0,   0,  ...,   0,   0,   0],\n",
       "        [  0,   0,   0,  ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchmetrics import Accuracy\n",
    " \n",
    "\n",
    "class TemplateModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.valid_accuracy = Accuracy()\n",
    "        self.test_accuracy = Accuracy()\n",
    "    \n",
    "    def forward(self, inputs, labels):\n",
    "        raise NotImplementedError(\"forward not implemented\")\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return [optimizer]\n",
    "    \n",
    "    def training_step(self, batch, _):\n",
    "        inputs, labels = batch\n",
    "        loss, logits = self(inputs, labels)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, _):\n",
    "        inputs, labels = batch\n",
    "        val_loss, logits = self(inputs, labels)\n",
    "        self.valid_accuracy.update(logits, labels)\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.valid_accuracy)\n",
    "\n",
    "    def validation_epoch_end(self, outs):\n",
    "        self.log(\"val_acc_epoch\", self.valid_accuracy.compute(), prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, _):\n",
    "        inputs, labels = batch\n",
    "        test_loss, logits = self(inputs, labels)\n",
    "        self.test_accuracy.update(logits, labels)\n",
    "        self.log(\"test_loss\", test_loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy)\n",
    "\n",
    "    def test_epoch_end(self, outs):\n",
    "        self.log(\"test_acc_epoch\", self.test_accuracy.compute(), prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spans(labels, tokens):\n",
    "    spans = []\n",
    "    for i, (label, token) in enumerate(zip(labels, tokens)):\n",
    "        if label == 1:\n",
    "            spans.append((token.start, token.stop, \"PER\"))\n",
    "        elif label == 2:\n",
    "            assert len(spans) != 0, \"Incorrect label sequence: {}\".format(labels)\n",
    "            old_begin, _, old_tag = spans[-1]\n",
    "            spans[-1] = (old_begin, token.stop, old_tag)\n",
    "    return spans\n",
    "\n",
    "\n",
    "def compare_span_sets(left_spans, right_spans):\n",
    "    exact, partial, missing = 0, 0, 0\n",
    "    for left_span in left_spans:\n",
    "        is_missing = True\n",
    "        for right_span in right_spans:\n",
    "            if left_span == right_span:\n",
    "                exact += 1\n",
    "                is_missing = False\n",
    "                break\n",
    "            ls, le, _ = left_span\n",
    "            rs, re, _ = right_span\n",
    "            # [ls le] [rs re]\n",
    "            # [rs re] [ls le]\n",
    "            if not (ls <= le <= rs <= re or rs <= re <= ls <= le):\n",
    "                is_missing = False\n",
    "                partial += 1\n",
    "                break            \n",
    "        if is_missing:\n",
    "            missing += 1\n",
    "    return exact, partial, missing\n",
    "\n",
    "\n",
    "def calc_metrics(true_labels, predicted_labels, tokens):\n",
    "    # Метрики классификации\n",
    "    one_tp, one_fp, one_fn = 0, 0, 0\n",
    "    for true, predicted in zip(true_labels, predicted_labels):\n",
    "        for l1, l2 in zip(true, predicted):\n",
    "            if l1 == 1 and l2 == 1:\n",
    "                one_tp += 1\n",
    "            elif l1 != 1 and l2 == 1:\n",
    "                one_fp += 1\n",
    "            elif l1 == 1 and l2 !=1:\n",
    "                one_fn += 1\n",
    "    if one_tp + one_fp == 0:\n",
    "        print(\"No positives!\")\n",
    "    else:\n",
    "        print(\"1 Precision: {}, 1 Recall: {}\".format(float(one_tp)/(one_tp + one_fp), float(one_tp)/(one_tp + one_fn)))\n",
    "\n",
    "    # Специализированные метрики\n",
    "    e, p, m, s = 0, 0, 0, 0\n",
    "    for (true, predicted), sample_tokens in zip(zip(true_labels, predicted_labels), tokens):\n",
    "        true_spans = get_spans(true, sample_tokens)\n",
    "        predicted_spans = get_spans(predicted, sample_tokens)\n",
    "        exact, partial, missing = compare_span_sets(true_spans, predicted_spans)\n",
    "        _, _, spurius = compare_span_sets(predicted_spans, true_spans)\n",
    "        e += exact\n",
    "        p += partial\n",
    "        m += missing #fn\n",
    "        s += spurius #fp\n",
    "    print(\"Exact: {}, partial: {}, missing: {}, spurius: {}\".format(e, p, m, s))\n",
    "            \n",
    "\n",
    "\n",
    "def predict(model, test_loader, show_sample_index=1):\n",
    "    model.eval()\n",
    "    all_true_labels, all_predicted_labels, all_tokens, all_texts = [], [], [], []\n",
    "    for batch_index, batch in enumerate(test_loader):\n",
    "        inputs, true_labels = batch\n",
    "        batch_size = inputs.size(0)\n",
    "        _, logits = model(inputs, true_labels)\n",
    "        predicted_labels = logits.max(dim=1)[1].detach().cpu()\n",
    "\n",
    "        # Убираем неконсистентность BIO\n",
    "        for sample_num, sample in enumerate(predicted_labels):\n",
    "            for token_num, label in enumerate(sample):\n",
    "                if token_num == 0 and label == 2:\n",
    "                    predicted_labels[sample_num][0] = 1\n",
    "                    continue\n",
    "                prev_label = sample[token_num - 1]\n",
    "                if label == 2 and prev_label == 0:\n",
    "                    predicted_labels[sample_num][token_num] = 1\n",
    "\n",
    "        all_true_labels.extend(true_labels)\n",
    "        all_predicted_labels.extend(predicted_labels)\n",
    "        for i in range(batch_size):\n",
    "            all_tokens.append(test_data.get_tokens(batch_index * batch_size + i))\n",
    "            all_texts.append(test_data.get_text(batch_index * batch_size + i))\n",
    "\n",
    "    calc_metrics(all_true_labels, all_predicted_labels, all_tokens)\n",
    "    print(\"PREDICTED:\")\n",
    "    show_box_markup(all_texts[show_sample_index],\n",
    "                    get_spans(all_predicted_labels[show_sample_index], all_tokens[show_sample_index]),\n",
    "                    palette=palette(PER=BLUE, ORG=RED, LOC=GREEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\nlp\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=10)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type             | Params\n",
      "------------------------------------------------------\n",
      "0 | loss             | CrossEntropyLoss | 0     \n",
      "1 | valid_accuracy   | Accuracy         | 0     \n",
      "2 | test_accuracy    | Accuracy         | 0     \n",
      "3 | embeddings_layer | Embedding        | 3.0 K \n",
      "4 | dropout          | Dropout          | 0     \n",
      "5 | linear           | Linear           | 3.2 K \n",
      "6 | relu             | ReLU             | 0     \n",
      "7 | lstm_layer       | LSTM             | 149 K \n",
      "8 | out_layer        | Linear           | 771   \n",
      "------------------------------------------------------\n",
      "156 K     Trainable params\n",
      "0         Non-trainable params\n",
      "156 K     Total params\n",
      "0.626     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\nlp\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "D:\\Anaconda\\envs\\nlp\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8421baaac48f4732a0df8d70bdf2a6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.023 >= min_delta = 0.0001. New best score: 0.073\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.0001. New best score: 0.062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0001. New best score: 0.057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0001. New best score: 0.053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0001. New best score: 0.049\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0001. New best score: 0.046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0001. New best score: 0.042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0001. New best score: 0.039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 8 records. Best score: 0.039. Signaling Trainer to stop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "D:\\Anaconda\\envs\\nlp\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bec93ac5cae4722ae171cf57f50fb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.9920492768287659\r\n",
      "     test_acc_epoch         0.9920492768287659\r\n",
      "        test_loss          0.022869132459163666\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.022869132459163666,\n",
       "  'test_acc': 0.9920492768287659,\n",
       "  'test_acc_epoch': 0.9920492768287659}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "class CharFFLstmModel(TemplateModel):\n",
    "    def __init__(self, char_set_size, char_embedding_dim=4, classes_count=3,\n",
    "                 word_embedding_dim=16, lstm_embedding_dim=256, char_max_seq_len=50):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeddings_layer = nn.Embedding(char_set_size, char_embedding_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(char_embedding_dim * char_max_seq_len, word_embedding_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm_layer = nn.LSTM(word_embedding_dim, lstm_embedding_dim // 2, batch_first=True, bidirectional=True)\n",
    "        self.out_layer = nn.Linear(lstm_embedding_dim, classes_count)\n",
    "\n",
    "    def forward(self, inputs, labels):\n",
    "        projections = self.embeddings_layer.forward(inputs)\n",
    "        projections = projections.reshape(projections.size(0), projections.size(1), -1)\n",
    "        projections = self.relu(self.linear(projections))\n",
    "        #projections = self.dropout(projections)\n",
    "        output, _= self.lstm_layer(projections)\n",
    "        output = self.dropout(output)\n",
    "        logits = self.out_layer(output)\n",
    "        logits = logits.transpose(1, 2)\n",
    "        loss = self.loss(logits, labels)\n",
    "        return loss, logits\n",
    "\n",
    "\n",
    "char_ff_lstm_model = CharFFLstmModel(len(char_set))\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.0001,\n",
    "    patience=8,\n",
    "    verbose=True,\n",
    "    mode=\"min\" \n",
    ")\n",
    "trainer = Trainer(\n",
    "    gpus=1,\n",
    "    enable_checkpointing=True,\n",
    "    accumulate_grad_batches=1,\n",
    "    max_epochs=150,\n",
    "    progress_bar_refresh_rate=10,\n",
    "    callbacks=[early_stop_callback])\n",
    "trainer.fit(char_ff_lstm_model, train_loader, val_loader)\n",
    "trainer.test(char_ff_lstm_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Precision: 0.6351028216164515, 1 Recall: 0.7022739291380222\n",
      "Exact: 1119, partial: 349, missing: 419, spurius: 592\n",
      "PREDICTED:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">Banknotes available: $1, $2, $5, $10, $20, $50, <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">$<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>100 ",
       "Central bank: Federal Reserve Bank ",
       "Tanzanian Shilling (TZS) is the official currency of Tanzania. ",
       "This currency is currently used by Tanzania This currency is pigged with: ",
       "Coins available: 1, 5, 10, 20, 50, 100, 200 shilingi ",
       "Banknotes available: 500, 1000, 2000, 5000, 10000 shilingi ",
       "Central bank: Bank of Tanzania ",
       "Nigerian Naira (NGN) is the official currency of Nigeria. ",
       "This currency is currently used by Nigeria This currency is pigged with: ",
       "Coins available: 50 kobo, 1 &amp; 2 naira</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(char_ff_lstm_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cd81547fa1daee83\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cd81547fa1daee83\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/version_2/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
